{
 "cells": [
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this part of the exercise we will be experimenting with modifying audio in various ways to stretch / shrink it through time and to modify it's pitch.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part A: Interpolating over time.\n",
    "\n",
    "1. load 'audio_16k/Basta_16k.wav' audio file (note that it is on stereo)\n",
    "2. use `torch.nn.functional.interpolate` with `mode='bilinear` to stretch / compress the signal with 1.2, 0.8 factor respectfully.\n",
    "3. save these samples to outputs directory as 'interpolation_0_8.wav', 'interpolation_1_2.wav' and listen to them, do you notice something odd? why do you think this happens? - answear in a markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the following file: outputs/interpolation_0_8.wav\n",
      "saving the following file: outputs/interpolation_1_2.wav\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "def create_if_not_exists(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "# create outputs dir\n",
    "OUTPUTS_DIR = \"outputs\"\n",
    "create_if_not_exists(OUTPUTS_DIR)\n",
    "\n",
    "# 1. load 'audio_16k/Basta_16k.wav' audio file (note that it is on stereo)\n",
    "y, sr = torchaudio.load(\"audio_16k/Basta_16k.wav\")\n",
    "\n",
    "SCALES = [0.8, 1.2]\n",
    "for stretch_scale in SCALES:\n",
    "    # F.interpolate expects 4D signals in bilinear mode\n",
    "    stretched_y = F.interpolate(y[None, None, :], mode='bilinear', scale_factor=stretch_scale)[0, 0, :]\n",
    "    outfile = f\"{OUTPUTS_DIR}/interpolation_{str(stretch_scale).replace('.', '_')}.wav\"\n",
    "    print(f\"saving the following file: {outfile}\")\n",
    "    torchaudio.save(outfile, stretched_y, sr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer non-code questions here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part B: Naive time stretch (tempo shift).\n",
    "\n",
    "In this part you would be required to write a function that perform a SIMPLE augmentation over the audio:\n",
    "1. `naive_tempo_shift(wav, factor)` = stretch an audiofile by a given factor, e.g 0.8 factor should result a slowdown to 0.8x the original audio (output a LONGER wav). \n",
    "2. load 'audio_16k/Basta_16k.wav' and generate a tempo shift of x{0.8, 1.2} and save these generated audio files to outputs/naive_pitch_shift_{factor using _ instead if .}.wav\n",
    "\n",
    "Note: This should be a Naive implementation, achieveable using torch.stft, torch.istft, torch.fft.fft, torch.fft.ifft alone and programable in a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 40\u001B[0m\n\u001B[1;32m     37\u001B[0m SCALES \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;241m1.2\u001B[39m]\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m stretch_scale \u001B[38;5;129;01min\u001B[39;00m SCALES:\n\u001B[0;32m---> 40\u001B[0m     y_stretched \u001B[38;5;241m=\u001B[39m \u001B[43mnaive_time_stretch\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstretch_scale\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     outfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mOUTPUTS_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/naive_pitch_shift_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(stretch_scale)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaving outfile: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[4], line 14\u001B[0m, in \u001B[0;36mnaive_time_stretch\u001B[0;34m(y, scale_factor)\u001B[0m\n\u001B[1;32m     12\u001B[0m WINDOW_SIZE \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m\n\u001B[1;32m     13\u001B[0m y_stft \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstft(y, n_fft\u001B[38;5;241m=\u001B[39mWINDOW_SIZE, return_complex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 14\u001B[0m ch, n_freqs, n_windows, _ \u001B[38;5;241m=\u001B[39m y_stft\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m     16\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m scale_factor\n\u001B[1;32m     17\u001B[0m soft_win_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "\n",
    "def create_if_not_exists(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "\n",
    "def naive_time_stretch(y, scale_factor):\n",
    "    WINDOW_SIZE = 1024\n",
    "    y_stft = torch.stft(y, n_fft=WINDOW_SIZE)\n",
    "    ch, n_freqs, n_windows, _ = y_stft.shape\n",
    "\n",
    "    step = 1 / scale_factor\n",
    "    soft_win_idx = 0.0\n",
    "    stretched_stft = None\n",
    "    k = 0\n",
    "    while(k < n_windows):\n",
    "        # jump by step, and concat original stft windows (downsampe/duplicate depending on scale_factor)\n",
    "        win_fft = y_stft[:, :, k, :].unsqueeze(2)\n",
    "        if stretched_stft is None:\n",
    "            stretched_stft = win_fft\n",
    "        else:\n",
    "            stretched_stft = torch.concat((stretched_stft, win_fft), dim=2)\n",
    "        soft_win_idx += step\n",
    "        k = int(round(soft_win_idx))\n",
    "\n",
    "    return torch.istft(stretched_stft, n_fft=WINDOW_SIZE)\n",
    "\n",
    "\n",
    "# create outputs dir\n",
    "OUTPUTS_DIR = \"outputs\"\n",
    "create_if_not_exists(OUTPUTS_DIR)\n",
    "y, sr = torchaudio.load(\"audio_16k/Basta_16k.wav\")\n",
    "SCALES = [0.8, 1.2]\n",
    "\n",
    "for stretch_scale in SCALES:\n",
    "    y_stretched = naive_time_stretch(y, scale_factor=stretch_scale)\n",
    "    outfile = f\"{OUTPUTS_DIR}/naive_pitch_shift_{str(stretch_scale).replace('.', '_')}.wav\"\n",
    "    print(f\"saving outfile: {outfile}\")\n",
    "    torchaudio.save(outfile, y_stretched, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part C: Phase vocoder\n",
    "In this subsection you will implement version of a slightly better algorithm to perform time_stretch called Phase vocoder.\n",
    "We do not aim to get into depth of this algorithm design, yet we think that this algorithm is cool to know so in this part you will implement it from a given pseudo code.\n",
    "\n",
    "1. Implement the algorithm following the pseudo code below for the function time_stretch.\n",
    "2. Load 'audio_16k/Basta_16k.wav' and use time_stretch with factors x0.8, 1.2, save these generations to `outputs/phase_vocoder_{factor, replace '.' with '_'}.wav`\n",
    "3. Do you notice anything different from the previous naive time stretch (besides magnitude differences)? why do you think it is different?\n",
    "\n",
    "Guidance: use torch, torchaudio functions in this section. \n",
    "\n",
    "-\n",
    "Pseudo code:\n",
    "-\n",
    "\n",
    "time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
    "    # create window\n",
    "    hann_window = construct_hann_window(win_size)\n",
    "\n",
    "    # draw two complex STFTs\n",
    "    new_hop = int(hop * factor)\n",
    "    stft_left = get_complex_stft(signal[:-hop], win_size, new_hop, hann_window)\n",
    "    stft_right = get_complex_stft(signal[hop:], win_size, new_hop, hann_window)\n",
    "\n",
    "    # calculate accumulated phase delta and reconstruct phase from it\n",
    "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
    "\n",
    "    # reconstruct component from phase\n",
    "    re, im = get_re_im_from_phase(phase)\n",
    "    complex_new_stft = view_as_complex(stack([re, im], dim=-1)) * abs(stft_right))\n",
    "    output = istft(complex_new_stft, win_length=win_size, hop_length=hop, window=hann_window)\n",
    "\n",
    "    return output\n",
    "\n",
    "-\n",
    "Pseudo functions:\n",
    "-\n",
    "\n",
    "construct_hann_window(win_size):\n",
    "    return a vector representing a hanning window, hint: see torch.hann_window\n",
    "\n",
    "get_complex_stft(signal, win_size, hop, window):\n",
    "    return a complex representation of the stft (x + jy form)\n",
    "\n",
    "get_acc_phase_delta(stft_left, stft_right):\n",
    "    # calculate angular distance between two complex STFTs\n",
    "    phase_delta = angle(stft_right) - angle(stft_left)\n",
    "\n",
    "    # accumulate phase, follow this recursive formula\n",
    "    for i in {1...length(phase_delta)}: phase[i] := phase_delta[i] + phase[i-1]; phase[0] = phase_delta[0]\n",
    "    \n",
    "    # round phase back to [-2 * pi, 2 * pi] range\n",
    "    phase = phase  - (2 * pi * round(phase_delta / (2 * pi)))  \n",
    "\n",
    "    return phase\n",
    "\n",
    "get_re_im_from_phase(phase):\n",
    "    retrieves the real and imaginary components from a complex phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import view_as_complex, istft, stack\n",
    "\n",
    "def construct_hann_window(win_size):\n",
    "    return torch.hann_window(win_size)\n",
    "\n",
    "def get_complex_stft(signal, win_size, hop, window):\n",
    "    return torch.stft(signal, n_fft=win_size, hop_length=hop, window=window, return_complex=True)\n",
    "\n",
    "def get_acc_phase_delta(stft_left, stft_right):\n",
    "    # calculate angular distance between two complex STFTs\n",
    "    phase_delta = torch.angle(stft_right) - torch.angle(stft_left)\n",
    "    # accumulate phase, follow this recursive formula\n",
    "    phase = torch.zeros_like(phase_delta)\n",
    "    phase[0] = phase_delta[0]\n",
    "    for i in range(1, len(phase_delta)):\n",
    "        phase[i] = phase_delta[i] + phase[i - 1]\n",
    "\n",
    "    # round phase back to [-2 * pi, 2 * pi] range\n",
    "    phase = phase - (2 * np.pi * np.round(phase / (2 * np.pi)))\n",
    "    return phase\n",
    "\n",
    "def get_re_im_from_phase(phase):\n",
    "    return torch.cos(phase), torch.sin(phase)\n",
    "\n",
    "def time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
    "    # create window\n",
    "    hann_window = construct_hann_window(win_size)\n",
    "\n",
    "    # draw two complex STFTs\n",
    "    new_hop = int(hop * factor)\n",
    "    stft_left = get_complex_stft(signal[:-hop], win_size, new_hop, hann_window)\n",
    "    stft_right = get_complex_stft(signal[hop:], win_size, new_hop, hann_window)\n",
    "\n",
    "    # calculate accumulated phase delta and reconstruct phase from it\n",
    "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
    "\n",
    "    # reconstruct component from phase\n",
    "    re, im = get_re_im_from_phase(phase)\n",
    "    output = torch.cat([re.unsqueeze(2), im.unsqueeze(2)], dim=2)\n",
    "\n",
    "    complex_new_stft = view_as_complex(\n",
    "        output * abs(stft_right).unsqueeze(-1)\n",
    "    )\n",
    "    output = istft(complex_new_stft, n_fft=win_size, hop_length=hop, window=hann_window)\n",
    "\n",
    "    return output\n",
    "\n",
    "def create_if_not_exists(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "OUTPUTS_DIR = \"outputs\"\n",
    "create_if_not_exists(OUTPUTS_DIR)\n",
    "y, sr = torchaudio.load(\"audio_16k/Basta_16k.wav\")\n",
    "SCALES = [0.8, 1.2]\n",
    "\n",
    "for stretch_scale in SCALES:\n",
    "    y_stretched = time_stretch(y[0], factor=stretch_scale)\n",
    "    outfile = f\"{OUTPUTS_DIR}/phase_vocoder_{str(stretch_scale).replace('.', '_')}.wav\"\n",
    "    print(f\"saving outfile: {outfile}\")\n",
    "    y_squeezed = torch.unsqueeze(y_stretched, 0)\n",
    "    stereo = torch.cat((y_squeezed, y_squeezed), dim=0)\n",
    "    torchaudio.save(outfile, stereo, sr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer non-code questions here\n",
    "\n",
    "it is different because we didnt naively strecthed the vector of the values - that changed the frequancies, but we screteched tyhe frequancies to osciliate longer (or less).\n",
    "if we would look at a simple sin(x) wave 1s length:\n",
    "- the naive approach is just like returning sin (factor * x).\n",
    "- the phase vecoder method is like changid the duration the the sin(x) is played."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
